***End-to-End Machine Learning Pipeline with API Deployment***
**Project Overview**

Building reliable and production-ready machine learning systems involves more than just training models. Common challenges include data leakage, which can inflate performance metrics, and model deployment, which requires integrating ML models into real-world systems while maintaining consistent performance over time.

This project demonstrates an end-to-end ML pipeline designed to address these challenges. It includes automated data preprocessing, model training, evaluation, and reporting, followed by deployment as an API that can be integrated into a web application or microservices architecture. The focus is on ML system reliability, reproducibility, and maintainability rather than on model complexity.

**Key Features**

Leakage-Protected ML Pipeline: Implements data preprocessing and model training steps designed to prevent data leakage.

Automated Reporting: Generates a performance report for each pipeline run.

API Deployment: Exposes the trained model via a REST API for use in web applications or other services.

Microservices Architecture: Separates Authentication, ML model, and Web App services for modularity and scalability.

Security Considerations: Implements authentication and secure handling of credentials.

**Objectives**

Build a robust ML pipeline that prevents data leakage and ensures reproducible model evaluation.

Deploy trained models in a production-like environment for real-world usage.

Document the pipeline and deployment workflow for future reference and reuse.

**Project Structure**

img/ – Images for README documentation.

result/ – Results and reports generated by the pipeline.

pipeline.py – Core Python script implementing the ML pipeline.

auth.py – Script to implement authentication service.

api.py – API endpoint to serve the trained model.

web_app.py – Web app interface for interacting with the model.

pipeline.bin – Serialized objects for the pipeline.

requirements.txt – List of required Python libraries.

README.md – Project documentation.

Data

This project uses the Iris dataset from the UCI Machine Learning Repository. The dataset is simple and ideal for demonstrating pipeline and deployment workflows.

Attributes:

sepal_length – Sepal length (cm)

sepal_width – Sepal width (cm)

petal_length – Petal length (cm)

petal_width – Petal width (cm)

class – Iris flower species

Technologies

Python, Pandas, Scikit-learn

FastAPI for API deployment

Microservices architecture

**Results**

<img width="2417" height="3017" alt="2023_05_25_metrics_result" src="https://github.com/user-attachments/assets/fa9c8220-f611-4ff7-925f-36b4f2016a23" />
